# MTSC 821: Scientific Computations
## Course Syllabus — Spring 2026

---

## Course Information

| | |
|---|---|
| **Course:** | MTSC 821 - Scientific Computations |
| **Semester:** | Spring 2026 |
| **Credits:** | 3 |
| **Meeting Time:** | TBD |
| **Location:** | TBD |

## Instructor Information

| | |
|---|---|
| **Instructor:** | Dr. Abdallah Alsammani |
| **Email:** | aalsammani@desu.edu |
| **Office:** | TBD |
| **Office Hours:** | By appointment |

---

## Course Description

This graduate course provides a rigorous foundation in scientific computing with emphasis on numerical linear algebra, optimization, and machine learning applications. Students will develop both theoretical understanding and practical implementation skills necessary for research in computational sciences.

## Course Objectives

By the end of this course, students will be able to:

1. **Understand** the mathematical foundations of linear algebra and their role in scientific computing
2. **Analyze** numerical algorithms for stability, accuracy, and computational complexity
3. **Implement** efficient algorithms for matrix computations and optimization
4. **Apply** scientific computing techniques to real-world problems in data science and machine learning
5. **Conduct** independent research leading to potential publication

---

## Course Topics

### Part I: Linear Algebra Foundations (Weeks 1-4)
- Vector spaces, bases, and dimension
- Linear transformations and matrices
- Matrix decompositions (LU, QR, Cholesky)
- Eigenvalue problems and spectral theory

### Part II: Numerical Linear Algebra (Weeks 5-7)
- Floating-point arithmetic and error analysis
- Conditioning and stability
- Iterative methods for linear systems
- Singular Value Decomposition (SVD)

### Part III: Optimization (Weeks 9-11)
- Unconstrained optimization
- Gradient descent and variants
- Newton and quasi-Newton methods
- Constrained optimization and KKT conditions

### Part IV: Applications (Weeks 12-13)
- Principal Component Analysis (PCA)
- Linear regression and regularization
- Neural networks and deep learning foundations
- Research applications

---

## Required Materials

### Textbooks
1. **Primary:** *Numerical Linear Algebra* by Trefethen & Bau (SIAM, 1997)
2. **Reference:** *Linear Algebra and Optimization for Machine Learning* by Aggarwal (Springer, 2020)
3. **Reference:** *Convex Optimization* by Boyd & Vandenberghe (Cambridge, 2004) — [Free PDF available](https://web.stanford.edu/~boyd/cvxbook/)

### Software
- Python 3.8+ with NumPy, SciPy, Matplotlib
- Jupyter Notebook/Lab
- LaTeX distribution (for reports)

---

## Grading Policy

| Component | Weight | Description |
|-----------|--------|-------------|
| **Homework** | 30% | 6 assignments, lowest dropped |
| **Midterm Exam** | 20% | In-class, Week 8 |
| **Research Project** | 35% | Semester-long project |
| **Final Presentation** | 15% | 25-minute research talk |

### Grade Scale

| Grade | Percentage | Grade | Percentage |
|-------|------------|-------|------------|
| A | 93-100% | C+ | 77-79% |
| A- | 90-92% | C | 73-76% |
| B+ | 87-89% | C- | 70-72% |
| B | 83-86% | D | 60-69% |
| B- | 80-82% | F | Below 60% |

---

## Assignments

### Homework
- Assigned weekly/bi-weekly
- Due at the beginning of class
- Late policy: 10% penalty per day, maximum 3 days late
- Collaboration encouraged, but write-ups must be individual

### Research Project
Students will complete a semester-long research project in one of four areas:

1. **Adaptive Streaming SVD** — Numerical Linear Algebra
2. **Geometry-Aware Hybrid Optimization** — Optimization Theory  
3. **Provably Convergent Sparse PCA** — Statistical Learning
4. **Spectral Learning Rate Adaptation** — Deep Learning

#### Project Timeline
| Milestone | Due Date | Weight |
|-----------|----------|--------|
| Proposal (2 pages) | Week 4 | 5% |
| Literature Review (5 pages) | Week 7 | 10% |
| Midterm Presentation | Week 8 | 5% |
| Draft Paper (8-10 pages) | Week 14 | 10% |
| Final Presentation | Week 15 | 15% |
| Final Submission | Post-semester | — |

---

## Course Policies

### Attendance
Regular attendance is expected. More than 3 unexcused absences may result in grade reduction.

### Academic Integrity
All work submitted must be your own. Plagiarism or cheating will result in a failing grade and referral to the Office of Student Conduct. When in doubt, cite your sources.

### Accommodations
Students requiring accommodations should contact Disability Support Services and provide documentation to the instructor within the first two weeks of class.

### Communication
- Course announcements via email and course website
- Questions about course material: office hours or email
- Response time: within 48 hours on business days

---

## Weekly Schedule

| Week | Dates | Topic | Assignments |
|------|-------|-------|-------------|
| 1 | Jan 13-17 | Vector Spaces & Bases | — |
| 2 | Jan 20-24 | Linear Maps & Matrices | HW1 Assigned |
| 3 | Jan 27-31 | Matrix Decompositions I | HW1 Due |
| 4 | Feb 3-7 | Matrix Decompositions II | Project Proposal Due |
| 5 | Feb 10-14 | Eigenvalues & Eigenvectors | HW2 Assigned |
| 6 | Feb 17-21 | SVD Theory | HW2 Due |
| 7 | Feb 24-28 | SVD Applications | Literature Review Due |
| 8 | Mar 2-6 | **Midterm Exam** | — |
| — | Mar 9-13 | *Spring Break* | — |
| 9 | Mar 16-20 | Optimization Fundamentals | HW3 Assigned |
| 10 | Mar 23-27 | Gradient Methods | HW3 Due |
| 11 | Mar 30-Apr 3 | Newton Methods | HW4 Assigned |
| 12 | Apr 6-10 | Constrained Optimization | HW4 Due |
| 13 | Apr 13-17 | ML Applications | Draft Paper Due |
| 14 | Apr 20-24 | Advanced Topics | HW5 Due |
| 15 | Apr 27-May 1 | **Final Presentations** | — |

---

## Additional Resources

### Online Resources
- Course GitHub Repository: [Link]
- MIT OpenCourseWare: Linear Algebra (18.06)
- Stanford CS229: Machine Learning

### Getting Help
- Office Hours: By appointment
- Email: aalsammani@desu.edu
- Study Groups: Encouraged!

---

*This syllabus is subject to change. Students will be notified of any modifications via email.*

**Last Updated:** January 2026
